<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Inner Page - iPortfolio Bootstrap Template</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Jul 27 2023 with Bootstrap v5.3.1
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Rachit Gandhi</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://twitter.com/UnknownAnony27" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://github.com/Rachit-Gandhi" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://www.instagram.com/fenetre_sur_la_vie/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://www.linkedin.com/in/rachit-gandhi27/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        </div>
      </div>


      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html/#hero" class="nav-link scrollto active"><i class="bx bx-home"></i>
              <span>Home</span></a></li>
          <li><a href="index.html/#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a>
          </li>
          <!-- <li><a href="#skills" class="nav-link scrollto"><i class='bx bxl-python'></i> <span>Skills</span></a></li> -->
          <li><a href="index.html/#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i>
              <span>Resume</span></a></li>
          <li><a href="blog.html" class="nav-link scrollto"><i class="bi bi-book-half"></i><span>Blog</span></a></li>
          <!-- <li><a href="#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> -->
          <!-- <span>Projects</span></a></li> -->
          <li><a href="index.html/#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i>
              <span>Contact</span></a></li>

        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Particle Filter</h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li><a href="blog.html">Blog</a></li>
            <li>Particle Filter</li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

<article id="7d73e75c-377b-4ad9-a500-44dfd6cfa658" class="page sans"><header><p class="page-description"></p><table class="properties"><tbody></tbody></table></header><div class="page-body"><h2 id="7da41106-cec2-4a2f-9b12-536158850417" class="">Unraveling the Magic of Particle Filters: From Blindfolded Games to Robot Pose Estimation</h2><img class = "img_head" src="assets/img/blog1_b.png" alt="Particle Filter"><br> <br><p id="8b7dc2ab-a2fc-40be-b28b-e2dc099777aa" class="">Have you ever found yourself in a dark room, blindfolded and spinning around, relying solely on your friends&#x27; shouts to avoid crashing into walls? It&#x27;s an exhilarating game that pushes your senses to the limit. But did you know that this game holds the key to understanding the fascinating world of particle filters and their role in helping robots estimate their poses in complex environments? Let&#x27;s dive into this captivating topic together!</p>
  </div></article>
  <article class="page sans">
  <img class = "img_head" src="assets/img/dark.jpg" alt="Particle Filter">
  <h2 id="eb736932-c1ef-499c-88ce-a1dd53c7658b" class="">Intuitive Understanding of the Particle Filter</h2><p id="9f594711-2f09-4693-961a-3bf25f8e8cd4" class="">Imagine being blindfolded and spun around like a top. It&#x27;s disorienting, to say the least. In this situation, you can&#x27;t rely on your vision. So, what can you rely on? Your friends, of course! As you stumble in the dark, your friends shout &quot;DANGER! DANGER!&quot; whenever you&#x27;re close to a wall, providing you with crucial cues about your surroundings. However, in a room, there are four walls, so you don&#x27;t know which one you&#x27;re facing. But fear not, there&#x27;s another sense you can use - your hearing. You listen carefully to the direction and distance of your friends&#x27; shouts or even their footsteps while running. With each event of &quot;DANGER&quot; and playful howling, your understanding of your position and orientation in the room improves. Your ultimate objective shifts from understanding your position to the exciting challenge of catching your friends. And as soon as you succeed, the blindfolded role switches to one of your friends.</p><p id="b7ae1dc6-547f-42a5-a496-740fb5bd8683" class="">Now, let&#x27;s draw parallels to the world of robotics. Imagine a robot placed in an environment, armed with a map of its surroundings, just like you had the layout of your own room. However, this robot has no idea about its own pose or what it may be facing. To assist the robot, we equip it with a powerful LIDAR sensor, providing two senses to rely on: the point cloud data of obstacles and a motion model.</p><p id="345e4296-baf4-4c13-8ea4-e7cc631792bb" class="">However, There&#x27;s a question to ponder here How reliable was your distance perception or your friends&#x27; cues during the blindfolded game?</p><p id="d19fae62-bee4-411b-af40-f2d25514da25" class="">If you&#x27;ve followed our previous blog series on the Kalman Filter (highly recommended), you&#x27;re aware that every sensor has noise, and leveraging multiple noisy observations leads to a better estimation.</p>
  </article>
  <article class="page sans">
    <p id="e44b250d-2702-4217-bb45-03bf82f97328" class="">In our scenario, both the LIDAR point clouds and the motion model introduce noise. Drawing on your familiarity with the Kalman Filter, you might think of using it to handle these noisy inputs and provide an estimated state. However, there&#x27;s an essential requirement - the noise must follow a specific probability distribution known as Gaussian. If the noise doesn&#x27;t fit this distribution, the Kalman Filter won&#x27;t be effective. But where does this non-Gaussian probability distribution is encoutered for that letâ€™s follow the robotics example with a few illustrations</p><h3 id="6d3b4b15-1bdc-4c7e-b4a9-a1635ad02f6d" class="">1. Initialization</h3><p id="3fa9cbe0-a69c-4735-8b13-9b251208bf36" class="">The first step in the Particle Filter algorithm is the initialization phase. The robot starts by scattering particles randomly throughout the space with random orientations. Each particle represents a probable pose of the robot. The number of particles used depends on the size and complexity of the explored space, but for simplicity, let&#x27;s consider 100 poses initially.</p><p id="61610d7e-9461-4adc-ad2e-e71b25a00763" class="">The random scattering of particles provides an initial approximation of the robot&#x27;s pose distribution in the environment. This distribution is called the &quot;prior distribution&quot; or the &quot;prior belief.&quot;</p><h3 id="9d2b26bc-b39f-43c0-9d0b-5c85ccf63bad" class="">2. Sensor Measurement</h3><p id="57acc6e7-69a8-4378-8363-9adf4fe773ba" class="">Once the particles are scattered, the journey begins with an initial sensor reading from the LIDAR, which provides information about the surroundings. For example, the robot may detect a flat wall straight ahead. This sensor measurement serves as a cue to refine the randomly scattered particles. It is not deterministic as many locations could give this reading even false positives from middle of room facing nothing.</p><p id="5e130dd8-edf4-440f-bd31-d667a65beb92" class="">Using the sensor measurement, the particles are weighted and then resampled, allocating more particles at positions and orientations where they are likely to encounter the observed feature (in this case, the straight wall). The resampling process aims to align the particles with the actual environment, increasing the likelihood of capturing the robot&#x27;s true pose.</p><p id="ae903bad-7caa-4a48-af9b-939d5080dde5" class="">But what exactly is a MOTION MODEL? In simple terms, it captures the relationship between an object&#x27;s current state (position and orientation) and its future state, considering factors like velocity, acceleration, and direction of movement. The motion model allows us to estimate or predict where the robot is likely to be in the future, given its current state and known control inputs.</p><h3 id="f744cc0d-ab8f-4e42-9bbd-d683e3631fe4" class="">3. Motion Model</h3><p id="78837e32-f9f5-4abc-a23d-c840eab66a5e" class="">As the robot moves, the particles move accordingly. The motion model comes into play to update the particle positions based on the known control inputs and the robot&#x27;s current state. The motion model captures the relationship between the robot&#x27;s current state (position and orientation) and its future state, considering factors like velocity, acceleration, and direction of movement.</p><p id="aa19ebe1-7a78-451a-affb-ed9b9344eb67" class="">By applying the motion model to each particle, the algorithm predicts where the particles are likely to be in the next time step. This prediction accounts for the robot&#x27;s expected movement, improving the estimation of the robot&#x27;s pose.</p><h3 id="bdeb893a-b3cc-42e3-8d18-2ca542150de1" class="">4. Monte Carlo Localization and Resampling</h3><p id="78dce44c-4fec-4f9e-8641-5403a823a9d4" class="">The Particle Filter algorithm performs the <strong>weight assignment step</strong>. Each particle is assigned a weight that reflects how well it aligns with the sensor measurements. The weight represents the likelihood of a particle being the true pose of the robot given the sensor data.</p><p id="8f79fe32-eaf9-4c06-b6a4-ebdf659278e9" class="">Particles that better match the sensor measurements receive higher weights, while particles that do not align well receive lower weights. This weight assignment is typically done by comparing the sensor measurement with the expected measurement at each particle&#x27;s pose.</p><p id="dd4e4736-5fde-4a43-aa2f-fde2e929da11" class="">The purpose of the weight assignment is to emphasize particles that are more likely to represent the true pose of the robot. It allows the algorithm to focus on particles that have a higher chance of capturing the actual state, filtering out less probable particles.</p><p id="65dc8826-d891-4316-92a2-a1bc96e27f74" class="">After the weight assignment, the Particle Filter algorithm performs resampling to generate a new set of particles for the next iteration. The resampling step aims to maintain a representative set of particles that better represents the true pose distribution.</p><p id="a367ce73-5365-4639-92d3-c9435266f85a" class="">The resampling process is based on the assigned weights. Particles with higher weights have a higher probability of being selected for the next generation, while particles with lower weights have a lower chance of being chosen.</p><p id="0b7bb696-77c2-4faa-b27b-be3b8ed29728" class="">Resampling helps concentrate the particles around areas of high probability, ensuring that the algorithm focuses on regions where the robot is likely to be located. This adaptive resampling enables the algorithm to adapt to changes in the environment and converge to a more accurate estimate of the robot&#x27;s pose.</p><h3 id="9b6415d0-6b66-426b-b7f5-9e947fe96564" class="">5. Non-Gaussian Distribution</h3><p id="3dd64808-01ca-4aed-89cd-7506d0cdf579" class="">Something we had promised before to touch on, letâ€™s bring back few of the old resampling illustrations. Can we call these distribution to be gaussian ? What is gaussian? Well this has been discussed in previous blogs,</p><p id="493156fa-a9e6-48ac-942c-1be7e8850cef" class="">In summary, Gaussian distributions are bell-shaped curves that represent symmetric data clustering around a mean, while non-Gaussian distributions encompass a broader range of shapes and patterns. Well using these illustrations itâ€™s obvious all the resampling makes the distribution to be non-gaussian, and the process of monte-carlo localisation and resampling is the main unit block in particle filters.</p><h3 id="3bd3f79b-92eb-4592-bb4c-c3c31037ad27" class="">6. Iteration</h3><p id="5a5c5ceb-8a8e-4ae6-8700-ccfc71101fdd" class="">The Particle Filter algorithm continues to iterate through the steps of motion prediction, weight assignment, and resampling. With each iteration, the particle filter refines the estimate of the robot&#x27;s pose.</p><p id="d0991ae7-c05f-4582-9d7a-900e71880546" class="">The process doesn&#x27;t end after a single iteration. Multiple iterations are performed to iteratively improve the estimation of the robot&#x27;s pose. As the iterations progress, the particles become increasingly concentrated around the true pose, providing a clearer understanding of the robot&#x27;s state.</p><p id="2d9f981f-51b8-45ce-a8a7-8f6da36d0df0" class="">The number of iterations required depends on the complexity of the environment, the quality of sensor measurements, and the desired level of accuracy. The algorithm continues until the estimated pose converges to a satisfactory level or until a specified stopping criterion is met.</p>
    </article>
    <article class="page sans">
      <h2 id="1b9f377f-2476-44d9-affd-74c8631bba00" class="">Conclusion</h2><p id="85732fed-196a-482c-b216-b302d1adfdc8" class="">In this blog, we explored the formal steps involved in the Particle Filter algorithm and gained a more detailed understanding of how it works. From the initialization and scattering of particles to the refinement through sensor measurements and motion models, each step contributes to improving the estimation of the robot&#x27;s pose.</p><p id="40d488d9-e920-465f-b6d6-70a6e4adf91f" class="">The process of weight assignment and resampling helps adaptively handle complex probability spaces, ensuring that the algorithm focuses on areas of high likelihood and filters out less probable particles.</p><p id="deef04d2-6471-4b92-b8bc-d1e53caaea4d" class="">Through iterations, the particle filter progressively refines its estimate, converging to a more accurate representation of the robot&#x27;s pose. This powerful algorithm has revolutionized the field of robotics and enables robots to effectively navigate and interact with their environments.</p><p id="fa063d4b-2073-45ca-8a1b-428b57254fd1" class="">So, the next time you encounter a robot estimating its pose in a complex environment, remember the magic of particle filters and how they rely on the interplay between sensor measurements, motion models, and resampling to unravel the robot&#x27;s state.</p><p id="d10a70f2-6ad9-4fd5-b87b-ef534ff639f3" class="">
</p></div></article>
  
    </section>
    <br>
  </main>
  <!--
        <section id="facts" class="facts">
          <div class="container">
        
          
      </main><nd #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>iPortfolio</span></strong>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>